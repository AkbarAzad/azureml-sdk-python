{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train and register model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Connect to workspace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "zpdsnfws02 Workspace loaded\n"
     ]
    }
   ],
   "source": [
    "# Connect to workspace\n",
    "from azureml.core import Workspace\n",
    "\n",
    "ws = Workspace.from_config()\n",
    "print(ws.name, \"Workspace loaded\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Upload data to datastores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "azureml_globaldatasets - Default = False\n",
      "workspaceartifactstore - Default = False\n",
      "workspaceblobstore - Default = True\n",
      "workspacefilestore - Default = False\n"
     ]
    }
   ],
   "source": [
    "# Get default datastores\n",
    "default_ds = ws.get_default_datastore()\n",
    "\n",
    "# Show all datastores\n",
    "for ds_name in ws.datastores:\n",
    "    print(ds_name, \"- Default =\", ds_name == default_ds.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploading an estimated of 1 files\n",
      "Uploading ./datasets/Marketing_Request_20210312.csv\n",
      "Uploaded ./datasets/Marketing_Request_20210312.csv, 1 files out of an estimated total of 1\n",
      "Uploaded 1 files\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "$AZUREML_DATAREFERENCE_0ba8fcd87d38467b8f7d9bb2b07aa7fb"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Upload data to a datastore\n",
    "default_ds.upload_files(files = [\"./datasets/Marketing_Request_20210312.csv\"], \\\n",
    "                        target_path = \"marketing-request-20210312-data/\", \\\n",
    "                        overwrite = True, show_progress = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "$AZUREML_DATAREFERENCE_f07ae46425ee4bd19c111d52e1cd53f0\n"
     ]
    }
   ],
   "source": [
    "# Train model from datastore\n",
    "data_ref = default_ds.path(\"marketing-request-20210312-data\").as_download()\n",
    "print(data_ref)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "marketing_request_20210312_from_datastore folder created\n"
     ]
    }
   ],
   "source": [
    "# Create folder for experiment files\n",
    "import os\n",
    "\n",
    "experiment_folder = \"marketing_request_20210312_from_datastore\"\n",
    "os.makedirs(experiment_folder, exist_ok = True)\n",
    "print(experiment_folder, \"folder created\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Write training script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting marketing_request_20210312_from_datastore/marketing_request_20210312_training.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile $experiment_folder/marketing_request_20210312_training.py\n",
    "# Import libraries\n",
    "import os \n",
    "import argparse\n",
    "from azureml.core import Run\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import joblib\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Parameterised training script\n",
    "# Get parameters\n",
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument(\"--data-folder\", type = str, dest = \"data_folder\", help = \"data folder reference\")\n",
    "args = parser.parse_args()\n",
    "\n",
    "# Get experiment run context\n",
    "run = Run.get_context()\n",
    "\n",
    "# Load data from data reference\n",
    "data_folder = args.data_folder\n",
    "print(\"Loading data from\", data_folder)\n",
    "# Load all files and concatenate into a single dataframe\n",
    "all_files = os.listdir(data_folder)\n",
    "marketing_request = pd.concat(pd.read_csv(os.path.join(data_folder, csv_file)) for csv_file in all_files)\n",
    "\n",
    "# Get features and labels\n",
    "X, y = marketing_request[[\"ACCESS_COUNT\", \"VOLUME\"]].values, marketing_request[\"USERS\"].values\n",
    "\n",
    "# Split into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.30, random_state = 123)\n",
    "\n",
    "# Train linear regression model\n",
    "print(\"Training a linear regression model with n_jobs None\")\n",
    "run.log(\"data_folder\", data_folder)\n",
    "model = LinearRegression().fit(X_train, y_train)\n",
    "\n",
    "# Calculate accuracy\n",
    "y_hat = model.predict(X_test)\n",
    "acc = np.average(y_hat == y_test)\n",
    "print(\"Accuracy:\", acc)\n",
    "run.log(\"Accuracy\", np.float(acc))\n",
    "\n",
    "# Calculate mean squared error\n",
    "y_scores = model.predict(X_test)\n",
    "mse = mean_squared_error(y_test, y_scores)\n",
    "run.log(\"MSE\", np.float(mse))\n",
    "\n",
    "# Store outputs\n",
    "os.makedirs(\"outputs\", exist_ok = True)\n",
    "joblib.dump(value = model, filename = \"outputs/marketing_request_20210312_model.pkl\")\n",
    "\n",
    "run.complete()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Run training script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:azureml.train.sklearn:'SKLearn' estimator is deprecated. Please use 'ScriptRunConfig' from 'azureml.core.script_run_config' with your own defined environment or the AzureML-Tutorial curated environment.\n",
      "WARNING:azureml.core.environment:'enabled' is deprecated. Please use the azureml.core.runconfig.DockerConfiguration object with the 'use_docker' param instead.\n",
      "WARNING:root:If 'script' has been provided here and a script file name has been specified in 'run_config', 'script' provided in ScriptRunConfig initialization will take precedence.\n",
      "WARNING:root:If 'arguments' has been provided here and arguments have been specified in 'run_config', 'arguments' provided in ScriptRunConfig initialization will take precedence.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "97ff7e8885d046148d63021933f40987",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "_UserRunWidget(widget_settings={'childWidgetDisplay': 'popup', 'send_telemetry': False, 'log_level': 'INFO', 'â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/aml.mini.widget.v1": "{\"status\": \"Completed\", \"workbench_run_details_uri\": \"https://ml.azure.com/runs/marketing_request_20210312_training_1632981655_e95fa4d1?wsid=/subscriptions/7f2548b2-47f8-4143-9312-72567cc7320d/resourcegroups/zpdsnfrg/workspaces/zpdsnfws02&tid=c85f1f61-79f7-42b4-ac8a-ccec45a10eef\", \"run_id\": \"marketing_request_20210312_training_1632981655_e95fa4d1\", \"run_properties\": {\"run_id\": \"marketing_request_20210312_training_1632981655_e95fa4d1\", \"created_utc\": \"2021-09-30T06:00:55.603358Z\", \"properties\": {\"_azureml.ComputeTargetType\": \"local\", \"ContentSnapshotId\": \"706cf15a-9958-4c5a-bf3e-031e5f14afd4\", \"azureml.git.repository_uri\": \"https://github.com/AkbarAzad/akbar_stock_analyser93.git\", \"mlflow.source.git.repoURL\": \"https://github.com/AkbarAzad/akbar_stock_analyser93.git\", \"azureml.git.branch\": \"master\", \"mlflow.source.git.branch\": \"master\", \"azureml.git.dirty\": \"True\"}, \"tags\": {}, \"script_name\": null, \"arguments\": null, \"end_time_utc\": \"2021-09-30T06:01:14.763458Z\", \"status\": \"Completed\", \"log_files\": {\"azureml-logs/60_control_log.txt\": \"https://zpdsnfwsstorage6aa052f07.blob.core.windows.net/azureml/ExperimentRun/dcid.marketing_request_20210312_training_1632981655_e95fa4d1/azureml-logs/60_control_log.txt?sv=2019-07-07&sr=b&sig=8sOFiwfnq1GprriKAP39rz5HKnrRKQUPMuKliPW4%2FhA%3D&st=2021-09-30T11%3A32%3A56Z&se=2021-09-30T19%3A42%3A56Z&sp=r\", \"azureml-logs/70_driver_log.txt\": \"https://zpdsnfwsstorage6aa052f07.blob.core.windows.net/azureml/ExperimentRun/dcid.marketing_request_20210312_training_1632981655_e95fa4d1/azureml-logs/70_driver_log.txt?sv=2019-07-07&sr=b&sig=PWydYhWmstQnE2bFaCmvtbta4KTy%2FLBh4I%2F4RhfNK%2BU%3D&st=2021-09-30T11%3A32%3A56Z&se=2021-09-30T19%3A42%3A56Z&sp=r\", \"logs/azureml/20060_azureml.log\": \"https://zpdsnfwsstorage6aa052f07.blob.core.windows.net/azureml/ExperimentRun/dcid.marketing_request_20210312_training_1632981655_e95fa4d1/logs/azureml/20060_azureml.log?sv=2019-07-07&sr=b&sig=higzC%2BvPYLKtx6MVGOVgqn2KcTQp5PZGBzQnyIh4suk%3D&st=2021-09-30T11%3A32%3A56Z&se=2021-09-30T19%3A42%3A56Z&sp=r\"}, \"log_groups\": [[\"azureml-logs/60_control_log.txt\"], [\"azureml-logs/70_driver_log.txt\"], [\"logs/azureml/20060_azureml.log\"]], \"run_duration\": \"0:00:19\", \"run_number\": \"10\", \"run_queued_details\": {\"status\": \"Completed\", \"details\": null}}, \"child_runs\": [], \"children_metrics\": {}, \"run_metrics\": [{\"name\": \"data_folder\", \"run_id\": \"marketing_request_20210312_training_1632981655_e95fa4d1\", \"categories\": [0], \"series\": [{\"data\": [\"/tmp/ea310b1c-15f7-438d-b93b-8c15d8783c67/0e5dc7c1-2711-4839-94dd-97637ce4f285/marketing-request-20210312-data\"]}]}, {\"name\": \"Accuracy\", \"run_id\": \"marketing_request_20210312_training_1632981655_e95fa4d1\", \"categories\": [0], \"series\": [{\"data\": [0.0]}]}, {\"name\": \"MSE\", \"run_id\": \"marketing_request_20210312_training_1632981655_e95fa4d1\", \"categories\": [0], \"series\": [{\"data\": [134839444.443378]}]}], \"run_logs\": \"2021-09-30 14:01:05,821|azureml|DEBUG|Inputs:: kwargs: {'OutputCollection': True, 'EnableMLflowTracking': True, 'snapshotProject': True}, track_folders: None, deny_list: None, directories_to_watch: ['logs', 'logs/azureml']\\r\\n2021-09-30 14:01:05,825|azureml.history._tracking.PythonWorkingDirectory|DEBUG|Execution target type: none\\r\\n2021-09-30 14:01:06,445|azureml.history._tracking.PythonWorkingDirectory|DEBUG|PySpark found in environment.\\r\\n2021-09-30 14:01:06,445|azureml.history._tracking.PythonWorkingDirectory.workingdir|DEBUG|Pinning working directory for filesystems: ['pyfs']\\r\\n2021-09-30 14:01:06,446|azureml.core.run|DEBUG|Identity in use is not set. Falling back to using AMLToken\\r\\n2021-09-30 14:01:06,446|azureml.core.run|DEBUG|Using AMLToken auth for remote run\\r\\n2021-09-30 14:01:06,446|azureml._restclient.service_context|DEBUG|Created a static thread pool for ServiceContext class\\r\\n2021-09-30 14:01:06,447|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://southeastasia.api.azureml.ms.\\r\\n2021-09-30 14:01:06,450|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://southeastasia.api.azureml.ms.\\r\\n2021-09-30 14:01:06,452|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://southeastasia.api.azureml.ms.\\r\\n2021-09-30 14:01:06,452|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://southeastasia.api.azureml.ms.\\r\\n2021-09-30 14:01:06,454|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://southeastasia.api.azureml.ms.\\r\\n2021-09-30 14:01:06,455|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://southeastasia.api.azureml.ms.\\r\\n2021-09-30 14:01:06,455|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://southeastasia.api.azureml.ms.\\r\\n2021-09-30 14:01:06,475|azureml.core._metrics|DEBUG|numpy.float128 is unsupported, expected for windows\\r\\n2021-09-30 14:01:06,518|azureml._SubmittedRun#marketing_request_20210312_training_1632981655_e95fa4d1.RunHistoryFacade.RunClient.get_by_exp_id-async:False|DEBUG|[START]\\r\\n2021-09-30 14:01:06,518|azureml._SubmittedRun#marketing_request_20210312_training_1632981655_e95fa4d1.RunHistoryFacade.RunClient|DEBUG|ClientBase: Calling get_by_exp_id with url /history/v1.0/subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/Microsoft.MachineLearningServices/workspaces/{workspaceName}/experimentids/{experimentId}/runs/{runId}\\r\\n2021-09-30 14:01:06,641|azureml._SubmittedRun#marketing_request_20210312_training_1632981655_e95fa4d1.RunHistoryFacade.RunClient.get_by_exp_id-async:False|DEBUG|[STOP]\\r\\n2021-09-30 14:01:06,641|azureml._SubmittedRun#marketing_request_20210312_training_1632981655_e95fa4d1|DEBUG|Constructing run from dto. type: azureml.scriptrun, source: None, props: {'_azureml.ComputeTargetType': 'local', 'ContentSnapshotId': '706cf15a-9958-4c5a-bf3e-031e5f14afd4', 'azureml.git.repository_uri': 'https://github.com/AkbarAzad/akbar_stock_analyser93.git', 'mlflow.source.git.repoURL': 'https://github.com/AkbarAzad/akbar_stock_analyser93.git', 'azureml.git.branch': 'master', 'mlflow.source.git.branch': 'master', 'azureml.git.dirty': 'True'}\\r\\n2021-09-30 14:01:06,649|azureml._SubmittedRun#marketing_request_20210312_training_1632981655_e95fa4d1.RunContextManager|DEBUG|Valid logs dir, setting up content loader\\r\\n2021-09-30 14:01:06,649|azureml|WARNING|Could not import azureml.mlflow or azureml.contrib.mlflow mlflow APIs will not run against AzureML services.  Add azureml-mlflow as a conda dependency for the run if this behavior is desired\\r\\n2021-09-30 14:01:06,649|azureml.WorkerPool|DEBUG|[START]\\r\\n2021-09-30 14:01:06,649|azureml.SendRunKillSignal|DEBUG|[START]\\r\\n2021-09-30 14:01:06,649|azureml.RunStatusContext|DEBUG|[START]\\r\\n2021-09-30 14:01:06,649|azureml._SubmittedRun#marketing_request_20210312_training_1632981655_e95fa4d1.RunContextManager.RunStatusContext|DEBUG|[START]\\r\\n2021-09-30 14:01:06,649|azureml.MetricsClient|DEBUG|[START]\\r\\n2021-09-30 14:01:06,649|azureml._SubmittedRun#marketing_request_20210312_training_1632981655_e95fa4d1.RunHistoryFacade.MetricsClient|DEBUG|[START]\\r\\n2021-09-30 14:01:06,649|azureml.ContentUploader|DEBUG|[START]\\r\\n2021-09-30 14:01:06,657|azureml._history.utils.context_managers|DEBUG|starting file watcher\\r\\n2021-09-30 14:01:06,660|azureml._history.utils.context_managers.FileWatcher.UploadQueue|DEBUG|[Start]\\r\\n2021-09-30 14:01:06,660|azureml.TrackFolders|DEBUG|[START]\\r\\n2021-09-30 14:01:06,661|azureml.WorkingDirectoryCM|DEBUG|[START]\\r\\n2021-09-30 14:01:06,661|azureml.history._tracking.PythonWorkingDirectory.workingdir|DEBUG|[START]\\r\\n2021-09-30 14:01:06,661|azureml.history._tracking.PythonWorkingDirectory|INFO|Current working dir: C:\\\\Users\\\\65961\\\\AppData\\\\Local\\\\Temp\\\\azureml_runs\\\\marketing_request_20210312_training_1632981655_e95fa4d1\\r\\n2021-09-30 14:01:06,662|azureml.history._tracking.PythonWorkingDirectory.workingdir|DEBUG|Calling pyfs\\r\\n2021-09-30 14:01:06,662|azureml.history._tracking.PythonWorkingDirectory.workingdir|DEBUG|Storing working dir for pyfs as C:\\\\Users\\\\65961\\\\AppData\\\\Local\\\\Temp\\\\azureml_runs\\\\marketing_request_20210312_training_1632981655_e95fa4d1\\r\\n2021-09-30 14:01:06,682|azureml._SubmittedRun#marketing_request_20210312_training_1632981655_e95fa4d1.RunHistoryFacade.ArtifactsClient.batch_create_empty_artifacts-async:False|DEBUG|[START]\\r\\n2021-09-30 14:01:06,682|azureml._SubmittedRun#marketing_request_20210312_training_1632981655_e95fa4d1.RunHistoryFacade.ArtifactsClient|DEBUG|ClientBase: Calling batch_create_empty_artifacts with url /artifact/v2.0/subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/Microsoft.MachineLearningServices/workspaces/{workspaceName}/artifacts/batch/metadata/{origin}/{container}\\r\\n2021-09-30 14:01:07,040|azureml._SubmittedRun#marketing_request_20210312_training_1632981655_e95fa4d1.RunHistoryFacade.ArtifactsClient.batch_create_empty_artifacts-async:False|DEBUG|[STOP]\\r\\n2021-09-30 14:01:07,115|azureml._history.utils.context_managers.FileWatcher|DEBUG|uploading data to container: azureml blob: ExperimentRun/dcid.marketing_request_20210312_training_1632981655_e95fa4d1/logs/azureml/20060_azureml.log path: C:\\\\Users\\\\65961\\\\AppData\\\\Local\\\\Temp\\\\azureml_runs\\\\marketing_request_20210312_training_1632981655_e95fa4d1\\\\logs\\\\azureml\\\\20060_azureml.log\\r\\n2021-09-30 14:01:07,118|azureml._history.utils.context_managers.FileWatcher.UploadQueue.WorkerPool|DEBUG|submitting future: result\\r\\n2021-09-30 14:01:07,119|azureml._history.utils.context_managers.FileWatcher.UploadQueue.0_result|DEBUG|Using basic handler - no exception handling\\r\\n2021-09-30 14:01:07,119|azureml._history.utils.context_managers.FileWatcher.UploadQueue|DEBUG|Adding task 0_result to queue of approximate size: 0\\r\\n2021-09-30 14:01:09,455|azureml.core.run|DEBUG|Identity in use is not set. Falling back to using AMLToken\\r\\n2021-09-30 14:01:09,455|azureml.core.run|DEBUG|Using AMLToken auth for remote run\\r\\n2021-09-30 14:01:09,455|azureml._restclient.service_context|DEBUG|Access an existing static threadpool for ServiceContext class\\r\\n2021-09-30 14:01:09,455|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://southeastasia.api.azureml.ms.\\r\\n2021-09-30 14:01:09,455|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://southeastasia.api.azureml.ms.\\r\\n2021-09-30 14:01:09,455|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://southeastasia.api.azureml.ms.\\r\\n2021-09-30 14:01:09,455|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://southeastasia.api.azureml.ms.\\r\\n2021-09-30 14:01:09,455|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://southeastasia.api.azureml.ms.\\r\\n2021-09-30 14:01:09,455|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://southeastasia.api.azureml.ms.\\r\\n2021-09-30 14:01:09,455|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://southeastasia.api.azureml.ms.\\r\\n2021-09-30 14:01:09,599|azureml._SubmittedRun#marketing_request_20210312_training_1632981655_e95fa4d1.RunHistoryFacade.RunClient.get_by_exp_id-async:False|DEBUG|[START]\\r\\n2021-09-30 14:01:09,599|azureml._SubmittedRun#marketing_request_20210312_training_1632981655_e95fa4d1.RunHistoryFacade.RunClient|DEBUG|ClientBase: Calling get_by_exp_id with url /history/v1.0/subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/Microsoft.MachineLearningServices/workspaces/{workspaceName}/experimentids/{experimentId}/runs/{runId}\\r\\n2021-09-30 14:01:09,692|azureml._SubmittedRun#marketing_request_20210312_training_1632981655_e95fa4d1.RunHistoryFacade.RunClient.get_by_exp_id-async:False|DEBUG|[STOP]\\r\\n2021-09-30 14:01:09,692|azureml._SubmittedRun#marketing_request_20210312_training_1632981655_e95fa4d1|DEBUG|Constructing run from dto. type: azureml.scriptrun, source: None, props: {'_azureml.ComputeTargetType': 'local', 'ContentSnapshotId': '706cf15a-9958-4c5a-bf3e-031e5f14afd4', 'azureml.git.repository_uri': 'https://github.com/AkbarAzad/akbar_stock_analyser93.git', 'mlflow.source.git.repoURL': 'https://github.com/AkbarAzad/akbar_stock_analyser93.git', 'azureml.git.branch': 'master', 'mlflow.source.git.branch': 'master', 'azureml.git.dirty': 'True'}\\r\\n2021-09-30 14:01:09,692|azureml._SubmittedRun#marketing_request_20210312_training_1632981655_e95fa4d1.RunContextManager|DEBUG|Valid logs dir, setting up content loader\\r\\n2021-09-30 14:01:10,488|azureml._SubmittedRun#marketing_request_20210312_training_1632981655_e95fa4d1.RunHistoryFacade.MetricsClient|DEBUG|Overrides: Max batch size: 50, batch cushion: 5, Interval: 1.\\r\\n2021-09-30 14:01:10,488|azureml._SubmittedRun#marketing_request_20210312_training_1632981655_e95fa4d1.RunHistoryFacade.MetricsClient.PostMetricsBatchV2.PostMetricsBatchV2Daemon|DEBUG|Starting daemon and triggering first instance\\r\\n2021-09-30 14:01:10,488|azureml._SubmittedRun#marketing_request_20210312_training_1632981655_e95fa4d1.RunHistoryFacade.MetricsClient|DEBUG|Used <class 'azureml._common.async_utils.batch_task_queue.BatchTaskQueue'> for use_batch=True.\\r\\n2021-09-30 14:01:10,555|azureml._SubmittedRun#marketing_request_20210312_training_1632981655_e95fa4d1|INFO|complete is not setting status for submitted runs.\\r\\n2021-09-30 14:01:10,555|azureml._SubmittedRun#marketing_request_20210312_training_1632981655_e95fa4d1.RunHistoryFacade.MetricsClient.FlushingMetricsClient|DEBUG|[START]\\r\\n2021-09-30 14:01:10,556|azureml._SubmittedRun#marketing_request_20210312_training_1632981655_e95fa4d1.RunHistoryFacade.MetricsClient|DEBUG|Overrides: Max batch size: 50, batch cushion: 5, Interval: 1.\\r\\n2021-09-30 14:01:10,556|azureml._SubmittedRun#marketing_request_20210312_training_1632981655_e95fa4d1.RunHistoryFacade.MetricsClient.PostMetricsBatch.PostMetricsBatchDaemon|DEBUG|Starting daemon and triggering first instance\\r\\n2021-09-30 14:01:10,556|azureml._SubmittedRun#marketing_request_20210312_training_1632981655_e95fa4d1.RunHistoryFacade.MetricsClient|DEBUG|Used <class 'azureml._common.async_utils.batch_task_queue.BatchTaskQueue'> for use_batch=True.\\r\\n2021-09-30 14:01:10,556|azureml._SubmittedRun#marketing_request_20210312_training_1632981655_e95fa4d1.RunHistoryFacade.MetricsClient.PostMetricsBatch.WaitFlushSource:MetricsClient|DEBUG|[START]\\r\\n2021-09-30 14:01:10,556|azureml._SubmittedRun#marketing_request_20210312_training_1632981655_e95fa4d1.RunHistoryFacade.MetricsClient.PostMetricsBatch.WaitFlushSource:MetricsClient|DEBUG|flush timeout 300 is different from task queue timeout 120, using flush timeout\\r\\n2021-09-30 14:01:10,556|azureml._SubmittedRun#marketing_request_20210312_training_1632981655_e95fa4d1.RunHistoryFacade.MetricsClient.PostMetricsBatch.WaitFlushSource:MetricsClient|DEBUG|Waiting 300 seconds on tasks: [].\\r\\n2021-09-30 14:01:10,556|azureml._SubmittedRun#marketing_request_20210312_training_1632981655_e95fa4d1.RunHistoryFacade.MetricsClient.PostMetricsBatch|DEBUG|\\r\\n2021-09-30 14:01:10,556|azureml._SubmittedRun#marketing_request_20210312_training_1632981655_e95fa4d1.RunHistoryFacade.MetricsClient.PostMetricsBatch.WaitFlushSource:MetricsClient|DEBUG|[STOP]\\r\\n2021-09-30 14:01:10,556|azureml.BatchTaskQueueAdd_1_Batches|DEBUG|[Start]\\r\\n2021-09-30 14:01:10,556|azureml.BatchTaskQueueAdd_1_Batches.WorkerPool|DEBUG|submitting future: _handle_batch\\r\\n2021-09-30 14:01:10,556|azureml._SubmittedRun#marketing_request_20210312_training_1632981655_e95fa4d1.RunHistoryFacade.MetricsClient.PostMetricsBatchV2|DEBUG|Batch size 3.\\r\\n2021-09-30 14:01:10,556|azureml.BatchTaskQueueAdd_1_Batches.0__handle_batch|DEBUG|Using basic handler - no exception handling\\r\\n2021-09-30 14:01:10,556|azureml._restclient.service_context.WorkerPool|DEBUG|submitting future: _log_batch_v2\\r\\n2021-09-30 14:01:10,556|azureml.BatchTaskQueueAdd_1_Batches|DEBUG|Adding task 0__handle_batch to queue of approximate size: 0\\r\\n2021-09-30 14:01:10,556|azureml.BatchTaskQueueAdd_1_Batches|DEBUG|[Stop] - waiting default timeout\\r\\n2021-09-30 14:01:10,556|azureml._SubmittedRun#marketing_request_20210312_training_1632981655_e95fa4d1.RunHistoryFacade.MetricsClient|DEBUG|Metrics Client: _log_batch_v2 is calling post_run_metrics posting 3 values.\\r\\n2021-09-30 14:01:10,556|azureml.BatchTaskQueueAdd_1_Batches.WaitFlushSource:BatchTaskQueueAdd_1_Batches|DEBUG|[START]\\r\\n2021-09-30 14:01:10,556|azureml._SubmittedRun#marketing_request_20210312_training_1632981655_e95fa4d1.RunHistoryFacade.MetricsClient.PostMetricsBatchV2.0__log_batch_v2|DEBUG|Using basic handler - no exception handling\\r\\n2021-09-30 14:01:10,556|azureml._SubmittedRun#marketing_request_20210312_training_1632981655_e95fa4d1.RunHistoryFacade.MetricsClient._post_run_metrics_log_failed_validations-async:False|DEBUG|[START]\\r\\n2021-09-30 14:01:10,556|azureml.BatchTaskQueueAdd_1_Batches.WaitFlushSource:BatchTaskQueueAdd_1_Batches|DEBUG|Overriding default flush timeout from None to 120\\r\\n2021-09-30 14:01:10,556|azureml._SubmittedRun#marketing_request_20210312_training_1632981655_e95fa4d1.RunHistoryFacade.MetricsClient.PostMetricsBatchV2|DEBUG|Adding task 0__log_batch_v2 to queue of approximate size: 0\\r\\n2021-09-30 14:01:10,556|azureml._SubmittedRun#marketing_request_20210312_training_1632981655_e95fa4d1.RunHistoryFacade.MetricsClient|DEBUG|ClientBase: Calling _post_run_metrics_log_failed_validations with url None\\r\\n2021-09-30 14:01:10,556|azureml.BatchTaskQueueAdd_1_Batches.WaitFlushSource:BatchTaskQueueAdd_1_Batches|DEBUG|Waiting 120 seconds on tasks: [AsyncTask(0__handle_batch)].\\r\\n2021-09-30 14:01:10,572|azureml.BatchTaskQueueAdd_1_Batches.0__handle_batch.WaitingTask|DEBUG|[START]\\r\\n2021-09-30 14:01:10,572|azureml.BatchTaskQueueAdd_1_Batches.0__handle_batch.WaitingTask|DEBUG|Awaiter is BatchTaskQueueAdd_1_Batches\\r\\n2021-09-30 14:01:10,572|azureml.BatchTaskQueueAdd_1_Batches.0__handle_batch.WaitingTask|DEBUG|[STOP]\\r\\n2021-09-30 14:01:10,572|azureml.BatchTaskQueueAdd_1_Batches|DEBUG|\\r\\n2021-09-30 14:01:10,572|azureml.BatchTaskQueueAdd_1_Batches.WaitFlushSource:BatchTaskQueueAdd_1_Batches|DEBUG|[STOP]\\r\\n2021-09-30 14:01:10,572|azureml._SubmittedRun#marketing_request_20210312_training_1632981655_e95fa4d1.RunHistoryFacade.MetricsClient.PostMetricsBatchV2.WaitFlushSource:MetricsClient|DEBUG|[START]\\r\\n2021-09-30 14:01:10,572|azureml._SubmittedRun#marketing_request_20210312_training_1632981655_e95fa4d1.RunHistoryFacade.MetricsClient.PostMetricsBatchV2.WaitFlushSource:MetricsClient|DEBUG|flush timeout 300 is different from task queue timeout 120, using flush timeout\\r\\n2021-09-30 14:01:10,579|azureml._SubmittedRun#marketing_request_20210312_training_1632981655_e95fa4d1.RunHistoryFacade.MetricsClient.PostMetricsBatchV2.WaitFlushSource:MetricsClient|DEBUG|Waiting 300 seconds on tasks: [AsyncTask(0__log_batch_v2)].\\r\\n2021-09-30 14:01:10,858|azureml._SubmittedRun#marketing_request_20210312_training_1632981655_e95fa4d1.RunHistoryFacade.MetricsClient._post_run_metrics_log_failed_validations-async:False|DEBUG|[STOP]\\r\\n2021-09-30 14:01:11,091|azureml._SubmittedRun#marketing_request_20210312_training_1632981655_e95fa4d1.RunHistoryFacade.MetricsClient.PostMetricsBatchV2.0__log_batch_v2.WaitingTask|DEBUG|[START]\\r\\n2021-09-30 14:01:11,091|azureml._SubmittedRun#marketing_request_20210312_training_1632981655_e95fa4d1.RunHistoryFacade.MetricsClient.PostMetricsBatchV2.0__log_batch_v2.WaitingTask|DEBUG|Awaiter is PostMetricsBatchV2\\r\\n2021-09-30 14:01:11,091|azureml._SubmittedRun#marketing_request_20210312_training_1632981655_e95fa4d1.RunHistoryFacade.MetricsClient.PostMetricsBatchV2.0__log_batch_v2.WaitingTask|DEBUG|[STOP]\\r\\n2021-09-30 14:01:11,091|azureml._SubmittedRun#marketing_request_20210312_training_1632981655_e95fa4d1.RunHistoryFacade.MetricsClient.PostMetricsBatchV2|DEBUG|Waiting on task: 0__log_batch_v2.\\r\\n1 tasks left. Current duration of flush 0.0 seconds.\\r\\nWaiting on task: 0__log_batch_v2.\\r\\n1 tasks left. Current duration of flush 0.256793737411499 seconds.\\r\\n\\r\\n2021-09-30 14:01:11,091|azureml._SubmittedRun#marketing_request_20210312_training_1632981655_e95fa4d1.RunHistoryFacade.MetricsClient.PostMetricsBatchV2.WaitFlushSource:MetricsClient|DEBUG|[STOP]\\r\\n2021-09-30 14:01:11,091|azureml._SubmittedRun#marketing_request_20210312_training_1632981655_e95fa4d1.RunHistoryFacade.MetricsClient.FlushingMetricsClient|DEBUG|[STOP]\\r\\n2021-09-30 14:01:11,091|azureml._SubmittedRun#marketing_request_20210312_training_1632981655_e95fa4d1.RunHistoryFacade.MetricsClient.wait_on_ingest-async:False|DEBUG|[START]\\r\\n2021-09-30 14:01:11,091|azureml._SubmittedRun#marketing_request_20210312_training_1632981655_e95fa4d1.RunHistoryFacade.MetricsClient|DEBUG|ClientBase: Calling wait_on_ingest with url /history/v1.0/subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/Microsoft.MachineLearningServices/workspaces/{workspaceName}/experiments/{experimentName}/runs/{runId}/metricsingest/wait\\r\\n2021-09-30 14:01:11,253|azureml._SubmittedRun#marketing_request_20210312_training_1632981655_e95fa4d1.RunHistoryFacade.MetricsClient.wait_on_ingest-async:False|DEBUG|[STOP]\\r\\n2021-09-30 14:01:11,253|azureml.history._tracking.PythonWorkingDirectory.workingdir|DEBUG|Uploading tracked directories: [], excluding []\\r\\n2021-09-30 14:01:11,253|azureml.history._tracking.PythonWorkingDirectory.workingdir|DEBUG|Calling track for pyfs\\r\\n2021-09-30 14:01:11,434|azureml.history._tracking.PythonWorkingDirectory.workingdir|DEBUG|Calling pyfs\\r\\n2021-09-30 14:01:11,434|azureml.history._tracking.PythonWorkingDirectory|INFO|Current working dir: C:\\\\Users\\\\65961\\\\AppData\\\\Local\\\\Temp\\\\azureml_runs\\\\marketing_request_20210312_training_1632981655_e95fa4d1\\r\\n2021-09-30 14:01:11,435|azureml.history._tracking.PythonWorkingDirectory.workingdir|DEBUG|Reverting working dir from C:\\\\Users\\\\65961\\\\AppData\\\\Local\\\\Temp\\\\azureml_runs\\\\marketing_request_20210312_training_1632981655_e95fa4d1 to C:\\\\Users\\\\65961\\\\AppData\\\\Local\\\\Temp\\\\azureml_runs\\\\marketing_request_20210312_training_1632981655_e95fa4d1\\r\\n2021-09-30 14:01:11,435|azureml.history._tracking.PythonWorkingDirectory|INFO|Working dir is already updated C:\\\\Users\\\\65961\\\\AppData\\\\Local\\\\Temp\\\\azureml_runs\\\\marketing_request_20210312_training_1632981655_e95fa4d1\\r\\n2021-09-30 14:01:11,435|azureml.history._tracking.PythonWorkingDirectory.workingdir|DEBUG|[STOP]\\r\\n2021-09-30 14:01:11,435|azureml.WorkingDirectoryCM|DEBUG|[STOP]\\r\\n2021-09-30 14:01:11,435|azureml.history._tracking.PythonWorkingDirectory.workingdir|DEBUG|Uploading tracked directories: ['./outputs'], excluding ['azureml-logs/driver_log']\\r\\n2021-09-30 14:01:11,435|azureml.history._tracking.PythonWorkingDirectory.workingdir|DEBUG|Calling track for pyfs\\r\\n2021-09-30 14:01:11,436|azureml.history._tracking.PythonWorkingDirectory|DEBUG|./outputs exists as directory, uploading..\\r\\n2021-09-30 14:01:11,437|azureml.history._tracking.PythonWorkingDirectory|DEBUG|Found and adding path to upload: ./outputs\\\\marketing_request_20210312_model.pkl\\r\\n2021-09-30 14:01:11,437|azureml.history._tracking.PythonWorkingDirectory|DEBUG|Paths to upload is ['./outputs\\\\\\\\marketing_request_20210312_model.pkl'] in dir ./outputs\\r\\n2021-09-30 14:01:11,437|azureml._SubmittedRun#marketing_request_20210312_training_1632981655_e95fa4d1.RunHistoryFacade.ArtifactsClient.upload_files|DEBUG|Overriding default timeout to 300\\r\\n2021-09-30 14:01:11,438|azureml._SubmittedRun#marketing_request_20210312_training_1632981655_e95fa4d1.RunHistoryFacade.ArtifactsClient.upload_files|DEBUG|[Start]\\r\\n2021-09-30 14:01:11,438|azureml._SubmittedRun#marketing_request_20210312_training_1632981655_e95fa4d1.RunHistoryFacade.ArtifactsClient.batch_create_empty_artifacts-async:False|DEBUG|[START]\\r\\n2021-09-30 14:01:11,438|azureml._SubmittedRun#marketing_request_20210312_training_1632981655_e95fa4d1.RunHistoryFacade.ArtifactsClient|DEBUG|ClientBase: Calling batch_create_empty_artifacts with url /artifact/v2.0/subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/Microsoft.MachineLearningServices/workspaces/{workspaceName}/artifacts/batch/metadata/{origin}/{container}\\r\\n2021-09-30 14:01:11,738|azureml._SubmittedRun#marketing_request_20210312_training_1632981655_e95fa4d1.RunHistoryFacade.ArtifactsClient.batch_create_empty_artifacts-async:False|DEBUG|[STOP]\\r\\n2021-09-30 14:01:11,738|azureml._restclient.service_context.WorkerPool|DEBUG|submitting future: perform_upload\\r\\n2021-09-30 14:01:11,738|azureml._SubmittedRun#marketing_request_20210312_training_1632981655_e95fa4d1.RunHistoryFacade.ArtifactsClient.upload_files.0_perform_upload|DEBUG|Using basic handler - no exception handling\\r\\n2021-09-30 14:01:11,738|azureml._SubmittedRun#marketing_request_20210312_training_1632981655_e95fa4d1.RunHistoryFacade.ArtifactsClient.upload_files|DEBUG|Adding task 0_perform_upload to queue of approximate size: 0\\r\\n2021-09-30 14:01:11,738|azureml._SubmittedRun#marketing_request_20210312_training_1632981655_e95fa4d1.RunHistoryFacade.ArtifactsClient.upload_files|DEBUG|[Stop] - waiting default timeout\\r\\n2021-09-30 14:01:11,738|azureml._SubmittedRun#marketing_request_20210312_training_1632981655_e95fa4d1.RunHistoryFacade.ArtifactsClient.upload_files.WaitFlushSource:upload_files|DEBUG|[START]\\r\\n2021-09-30 14:01:11,738|azureml._SubmittedRun#marketing_request_20210312_training_1632981655_e95fa4d1.RunHistoryFacade.ArtifactsClient.upload_files.WaitFlushSource:upload_files|DEBUG|Overriding default flush timeout from None to 300\\r\\n2021-09-30 14:01:11,738|azureml._restclient.clientbase|DEBUG|ClientBase: Calling create_blob_from_stream with url None\\r\\n2021-09-30 14:01:11,738|azureml._SubmittedRun#marketing_request_20210312_training_1632981655_e95fa4d1.RunHistoryFacade.ArtifactsClient.upload_files.WaitFlushSource:upload_files|DEBUG|Waiting 300 seconds on tasks: [AsyncTask(0_perform_upload)].\\r\\n2021-09-30 14:01:11,883|azureml._file_utils.upload|DEBUG|Uploaded blob ExperimentRun/dcid.marketing_request_20210312_training_1632981655_e95fa4d1/outputs/marketing_request_20210312_model.pkl with size 588, file size 588.\\r\\n2021-09-30 14:01:11,994|azureml._SubmittedRun#marketing_request_20210312_training_1632981655_e95fa4d1.RunHistoryFacade.ArtifactsClient.upload_files.0_perform_upload.WaitingTask|DEBUG|[START]\\r\\n2021-09-30 14:01:11,994|azureml._SubmittedRun#marketing_request_20210312_training_1632981655_e95fa4d1.RunHistoryFacade.ArtifactsClient.upload_files.0_perform_upload.WaitingTask|DEBUG|Awaiter is upload_files\\r\\n2021-09-30 14:01:11,994|azureml._SubmittedRun#marketing_request_20210312_training_1632981655_e95fa4d1.RunHistoryFacade.ArtifactsClient.upload_files.0_perform_upload.WaitingTask|DEBUG|[STOP]\\r\\n2021-09-30 14:01:11,994|azureml._SubmittedRun#marketing_request_20210312_training_1632981655_e95fa4d1.RunHistoryFacade.ArtifactsClient.upload_files|DEBUG|Waiting on task: 0_perform_upload.\\r\\n1 tasks left. Current duration of flush 0.0 seconds.\\r\\n\\r\\n2021-09-30 14:01:11,994|azureml._SubmittedRun#marketing_request_20210312_training_1632981655_e95fa4d1.RunHistoryFacade.ArtifactsClient.upload_files.WaitFlushSource:upload_files|DEBUG|[STOP]\\r\\n2021-09-30 14:01:11,994|azureml.TrackFolders|DEBUG|[STOP]\\r\\n2021-09-30 14:01:11,994|azureml._history.utils.context_managers|DEBUG|exiting ContentUploader, waiting for file_watcher to finish upload...\\r\\n2021-09-30 14:01:11,994|azureml._history.utils.context_managers.FileWatcher|DEBUG|FileWatcher called finish, setting event\\r\\n2021-09-30 14:01:11,994|azureml._history.utils.context_managers.FileWatcher|DEBUG|FileWatcher received exit event, getting current_stat\\r\\n2021-09-30 14:01:11,994|azureml._history.utils.context_managers.FileWatcher.UploadQueue.WorkerPool|DEBUG|submitting future: result\\r\\n2021-09-30 14:01:11,994|azureml._history.utils.context_managers.FileWatcher.UploadQueue.1_result|DEBUG|Using basic handler - no exception handling\\r\\n2021-09-30 14:01:11,994|azureml._history.utils.context_managers.FileWatcher.UploadQueue|DEBUG|Adding task 1_result to queue of approximate size: 1\\r\\n2021-09-30 14:01:11,994|azureml._history.utils.context_managers.FileWatcher|DEBUG|FileWatcher retrieved current_stat, will upload to current_stat\\r\\n2021-09-30 14:01:11,994|azureml._history.utils.context_managers.FileWatcher|DEBUG|FileWatcher uploading files to current_stat...\\r\\n2021-09-30 14:01:11,994|azureml._history.utils.context_managers.FileWatcher|DEBUG|FileWatcher uploading files to current_stat...\\r\\n2021-09-30 14:01:12,008|azureml._history.utils.context_managers.FileWatcher|DEBUG|FileWatcher uploading files to current_stat...\\r\\n2021-09-30 14:01:12,008|azureml._history.utils.context_managers.FileWatcher|DEBUG|FileWatcher uploading files to current_stat...\\r\\n2021-09-30 14:01:12,008|azureml._history.utils.context_managers.FileWatcher|DEBUG|FileWatcher uploading files to current_stat...\\r\\n2021-09-30 14:01:12,008|azureml._history.utils.context_managers.FileWatcher|DEBUG|FileWatcher uploading files to current_stat...\\r\\n2021-09-30 14:01:12,008|azureml._history.utils.context_managers.FileWatcher|DEBUG|FileWatcher uploading files to current_stat...\\r\\n2021-09-30 14:01:12,008|azureml._history.utils.context_managers.FileWatcher|DEBUG|FileWatcher uploading files to current_stat...\\r\\n2021-09-30 14:01:12,040|azureml._history.utils.context_managers.FileWatcher|DEBUG|FileWatcher uploading files to current_stat...\\r\\n2021-09-30 14:01:12,040|azureml._history.utils.context_managers.FileWatcher|DEBUG|FileWatcher uploading files to current_stat...\\r\\n2021-09-30 14:01:12,040|azureml._history.utils.context_managers.FileWatcher|DEBUG|FileWatcher uploading files to current_stat...\\r\\n2021-09-30 14:01:12,049|azureml._history.utils.context_managers.FileWatcher|DEBUG|FileWatcher uploading files to current_stat...\\r\\n2021-09-30 14:01:12,052|azureml._history.utils.context_managers.FileWatcher|DEBUG|FileWatcher uploading files to current_stat...\\r\\n2021-09-30 14:01:12,054|azureml._history.utils.context_managers.FileWatcher|DEBUG|FileWatcher uploading files to current_stat...\\r\\n2021-09-30 14:01:12,056|azureml._history.utils.context_managers.FileWatcher|DEBUG|FileWatcher uploading files to current_stat...\\r\\n2021-09-30 14:01:12,059|azureml._history.utils.context_managers.FileWatcher.UploadQueue.WorkerPool|DEBUG|submitting future: result\\r\\n2021-09-30 14:01:12,059|azureml._history.utils.context_managers.FileWatcher.UploadQueue.2_result|DEBUG|Using basic handler - no exception handling\\r\\n2021-09-30 14:01:12,059|azureml._history.utils.context_managers.FileWatcher.UploadQueue|DEBUG|Adding task 2_result to queue of approximate size: 2\\r\\n2021-09-30 14:01:12,059|azureml._history.utils.context_managers.FileWatcher|DEBUG|FileWatcher finished uploading to current_stat, finishing task queue\\r\\n2021-09-30 14:01:12,059|azureml._history.utils.context_managers.FileWatcher.UploadQueue|DEBUG|[Stop] - waiting default timeout\\r\\n2021-09-30 14:01:12,059|azureml._history.utils.context_managers.FileWatcher.UploadQueue.WaitFlushSource:UploadQueue|DEBUG|[START]\\r\\n2021-09-30 14:01:12,059|azureml._history.utils.context_managers.FileWatcher.UploadQueue.WaitFlushSource:UploadQueue|DEBUG|Overriding default flush timeout from None to 120\\r\\n2021-09-30 14:01:12,059|azureml._history.utils.context_managers.FileWatcher.UploadQueue.WaitFlushSource:UploadQueue|DEBUG|Waiting 120 seconds on tasks: [AsyncTask(0_result), AsyncTask(1_result), AsyncTask(2_result)].\\r\\n2021-09-30 14:01:12,059|azureml._history.utils.context_managers.FileWatcher.UploadQueue.0_result.WaitingTask|DEBUG|[START]\\r\\n2021-09-30 14:01:12,059|azureml._history.utils.context_managers.FileWatcher.UploadQueue.0_result.WaitingTask|DEBUG|Awaiter is UploadQueue\\r\\n2021-09-30 14:01:12,059|azureml._history.utils.context_managers.FileWatcher.UploadQueue.0_result.WaitingTask|DEBUG|[STOP]\\r\\n2021-09-30 14:01:12,059|azureml._history.utils.context_managers.FileWatcher.UploadQueue.1_result.WaitingTask|DEBUG|[START]\\r\\n2021-09-30 14:01:12,059|azureml._history.utils.context_managers.FileWatcher.UploadQueue.1_result.WaitingTask|DEBUG|Awaiter is UploadQueue\\r\\n2021-09-30 14:01:12,059|azureml._history.utils.context_managers.FileWatcher.UploadQueue.1_result.WaitingTask|DEBUG|[STOP]\\r\\n2021-09-30 14:01:12,325|azureml._history.utils.context_managers.FileWatcher.UploadQueue.2_result.WaitingTask|DEBUG|[START]\\r\\n2021-09-30 14:01:12,326|azureml._history.utils.context_managers.FileWatcher.UploadQueue.2_result.WaitingTask|DEBUG|Awaiter is UploadQueue\\r\\n2021-09-30 14:01:12,326|azureml._history.utils.context_managers.FileWatcher.UploadQueue.2_result.WaitingTask|DEBUG|[STOP]\\r\\n2021-09-30 14:01:12,326|azureml._history.utils.context_managers.FileWatcher.UploadQueue|DEBUG|Waiting on task: 2_result.\\r\\n1 tasks left. Current duration of flush 0.0 seconds.\\r\\n\\r\\n2021-09-30 14:01:12,326|azureml._history.utils.context_managers.FileWatcher.UploadQueue.WaitFlushSource:UploadQueue|DEBUG|[STOP]\\r\\n\\nRun is completed.\", \"graph\": {}, \"widget_settings\": {\"childWidgetDisplay\": \"popup\", \"send_telemetry\": false, \"log_level\": \"INFO\", \"sdk_version\": \"1.34.0\"}, \"loading\": false}"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'runId': 'marketing_request_20210312_training_1632981655_e95fa4d1',\n",
       " 'target': 'local',\n",
       " 'status': 'Finalizing',\n",
       " 'startTimeUtc': '2021-09-30T06:00:58.402748Z',\n",
       " 'services': {},\n",
       " 'properties': {'_azureml.ComputeTargetType': 'local',\n",
       "  'ContentSnapshotId': '706cf15a-9958-4c5a-bf3e-031e5f14afd4',\n",
       "  'azureml.git.repository_uri': 'https://github.com/AkbarAzad/akbar_stock_analyser93.git',\n",
       "  'mlflow.source.git.repoURL': 'https://github.com/AkbarAzad/akbar_stock_analyser93.git',\n",
       "  'azureml.git.branch': 'master',\n",
       "  'mlflow.source.git.branch': 'master',\n",
       "  'azureml.git.dirty': 'True'},\n",
       " 'inputDatasets': [],\n",
       " 'outputDatasets': [],\n",
       " 'runDefinition': {'script': 'marketing_request_20210312_training.py',\n",
       "  'command': '',\n",
       "  'useAbsolutePath': False,\n",
       "  'arguments': ['--data-folder',\n",
       "   '$AZUREML_DATAREFERENCE_f41e063e1190420e85c4e42c400cdbbc'],\n",
       "  'sourceDirectoryDataStore': None,\n",
       "  'framework': 'Python',\n",
       "  'communicator': 'None',\n",
       "  'target': 'local',\n",
       "  'dataReferences': {'f41e063e1190420e85c4e42c400cdbbc': {'dataStoreName': 'workspaceblobstore',\n",
       "    'mode': 'Download',\n",
       "    'pathOnDataStore': 'marketing-request-20210312-data',\n",
       "    'pathOnCompute': None,\n",
       "    'overwrite': False}},\n",
       "  'data': {},\n",
       "  'outputData': {},\n",
       "  'datacaches': [],\n",
       "  'jobName': None,\n",
       "  'maxRunDurationSeconds': None,\n",
       "  'nodeCount': 1,\n",
       "  'instanceTypes': [],\n",
       "  'priority': None,\n",
       "  'credentialPassthrough': False,\n",
       "  'identity': None,\n",
       "  'environment': {'name': 'Experiment marketing_request_20210312_training Environment',\n",
       "   'version': 'Autosave_2021-09-29T08:59:36Z_e62a291a',\n",
       "   'python': {'interpreterPath': 'python',\n",
       "    'userManagedDependencies': False,\n",
       "    'condaDependencies': {'channels': ['anaconda', 'conda-forge'],\n",
       "     'dependencies': ['python=3.6.2',\n",
       "      {'pip': ['azureml-defaults',\n",
       "        'scikit-learn==0.20.3',\n",
       "        'scipy==1.2.1',\n",
       "        'joblib==0.13.2']},\n",
       "      'pandas',\n",
       "      'pyspark'],\n",
       "     'name': 'azureml_a1949c73d55167b92412f960d4c55ff1'},\n",
       "    'baseCondaEnvironment': None},\n",
       "   'environmentVariables': {'EXAMPLE_ENV_VAR': 'EXAMPLE_VALUE'},\n",
       "   'docker': {'baseImage': 'mcr.microsoft.com/azureml/intelmpi2018.3-ubuntu16.04:20200423.v1',\n",
       "    'platform': {'os': 'Linux', 'architecture': 'amd64'},\n",
       "    'baseDockerfile': None,\n",
       "    'baseImageRegistry': {'address': None, 'username': None, 'password': None},\n",
       "    'enabled': True,\n",
       "    'arguments': []},\n",
       "   'spark': {'repositories': [], 'packages': [], 'precachePackages': False},\n",
       "   'inferencingStackVersion': None},\n",
       "  'history': {'outputCollection': True,\n",
       "   'directoriesToWatch': ['logs'],\n",
       "   'enableMLflowTracking': True,\n",
       "   'snapshotProject': True},\n",
       "  'spark': {'configuration': {'spark.app.name': 'Azure ML Experiment',\n",
       "    'spark.yarn.maxAppAttempts': '1'}},\n",
       "  'parallelTask': {'maxRetriesPerWorker': 0,\n",
       "   'workerCountPerNode': 1,\n",
       "   'terminalExitCodes': None,\n",
       "   'configuration': {}},\n",
       "  'amlCompute': {'name': None,\n",
       "   'vmSize': None,\n",
       "   'retainCluster': False,\n",
       "   'clusterMaxNodeCount': 1,\n",
       "   'location': None},\n",
       "  'aiSuperComputer': {'instanceType': 'D2',\n",
       "   'imageVersion': 'pytorch-1.7.0',\n",
       "   'location': None,\n",
       "   'aiSuperComputerStorageData': None,\n",
       "   'interactive': False,\n",
       "   'scalePolicy': None,\n",
       "   'virtualClusterArmId': None,\n",
       "   'tensorboardLogDirectory': None,\n",
       "   'sshPublicKey': None,\n",
       "   'enableAzmlInt': True,\n",
       "   'priority': 'Medium',\n",
       "   'slaTier': 'Standard',\n",
       "   'userAlias': None},\n",
       "  'kubernetesCompute': {'instanceType': None},\n",
       "  'tensorflow': {'workerCount': 1, 'parameterServerCount': 1},\n",
       "  'mpi': {'processCountPerNode': 1},\n",
       "  'pyTorch': {'communicationBackend': 'nccl', 'processCount': None},\n",
       "  'hdi': {'yarnDeployMode': 'Cluster'},\n",
       "  'containerInstance': {'region': None, 'cpuCores': 2.0, 'memoryGb': 3.5},\n",
       "  'exposedPorts': None,\n",
       "  'docker': {'useDocker': False,\n",
       "   'sharedVolumes': True,\n",
       "   'shmSize': '2g',\n",
       "   'arguments': []},\n",
       "  'cmk8sCompute': {'configuration': {}},\n",
       "  'commandReturnCodeConfig': {'returnCode': 'Zero',\n",
       "   'successfulReturnCodes': []},\n",
       "  'environmentVariables': {},\n",
       "  'applicationEndpoints': {},\n",
       "  'parameters': [],\n",
       "  'dataBricks': {'workers': 0,\n",
       "   'minimumWorkerCount': 0,\n",
       "   'maxMumWorkerCount': 0,\n",
       "   'sparkVersion': '4.0.x-scala2.11',\n",
       "   'nodeTypeId': 'Standard_D3_v2',\n",
       "   'sparkConf': {},\n",
       "   'sparkEnvVars': {},\n",
       "   'instancePoolId': None,\n",
       "   'timeoutSeconds': 0,\n",
       "   'jarLibraries': [],\n",
       "   'eggLibraries': [],\n",
       "   'whlLibraries': [],\n",
       "   'pypiLibraries': [],\n",
       "   'rCranLibraries': [],\n",
       "   'mavenLibraries': []}},\n",
       " 'logFiles': {'azureml-logs/60_control_log.txt': 'https://zpdsnfwsstorage6aa052f07.blob.core.windows.net/azureml/ExperimentRun/dcid.marketing_request_20210312_training_1632981655_e95fa4d1/azureml-logs/60_control_log.txt?sv=2019-07-07&sr=b&sig=Wb%2FYu3PLH%2Bw5O10TdxmL80m72C6B0e0UIV%2FQ9ICwo%2Bs%3D&st=2021-09-30T05%3A51%3A12Z&se=2021-09-30T14%3A01%3A12Z&sp=r',\n",
       "  'azureml-logs/70_driver_log.txt': 'https://zpdsnfwsstorage6aa052f07.blob.core.windows.net/azureml/ExperimentRun/dcid.marketing_request_20210312_training_1632981655_e95fa4d1/azureml-logs/70_driver_log.txt?sv=2019-07-07&sr=b&sig=aTK4pS%2FTyIUYltbzQjjp9iFo2RqhNWktytgUGqhWZNs%3D&st=2021-09-30T05%3A51%3A12Z&se=2021-09-30T14%3A01%3A12Z&sp=r',\n",
       "  'logs/azureml/20060_azureml.log': 'https://zpdsnfwsstorage6aa052f07.blob.core.windows.net/azureml/ExperimentRun/dcid.marketing_request_20210312_training_1632981655_e95fa4d1/logs/azureml/20060_azureml.log?sv=2019-07-07&sr=b&sig=bt9u0nKCkd0ZyAS2pmH%2Be3RBSxW36jlrVlNvd8Vw3Wg%3D&st=2021-09-30T05%3A51%3A10Z&se=2021-09-30T14%3A01%3A10Z&sp=r'},\n",
       " 'submittedBy': 'Akbar Azad'}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create estimator to run script\n",
    "from azureml.train.sklearn import SKLearn\n",
    "from azureml.core import Experiment\n",
    "from azureml.widgets import RunDetails\n",
    "import pandas as pd\n",
    "\n",
    "data_ref = default_ds.path(\"marketing-request-20210312-data\").as_download()\n",
    "\n",
    "# Set script parameters\n",
    "script_params = {\n",
    "    \"--data-folder\": data_ref\n",
    "}\n",
    "\n",
    "# Create estimator\n",
    "estimator = SKLearn(source_directory = experiment_folder,\n",
    "                   entry_script = \"marketing_request_20210312_training.py\",\n",
    "                   script_params = script_params,\n",
    "                   compute_target = \"local\",\n",
    "                    conda_packages = [\"pandas\", \"pyspark\"]\n",
    "                   )\n",
    "\n",
    "# Create experiment\n",
    "experiment_name = \"marketing_request_20210312_training\"\n",
    "experiment = Experiment(workspace = ws, name = experiment_name)\n",
    "\n",
    "# Run experiment\n",
    "run = experiment.submit(config = estimator)\n",
    "\n",
    "# Show run details\n",
    "RunDetails(run).show()\n",
    "run.wait_for_completion()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Register model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model trained and registered.\n"
     ]
    }
   ],
   "source": [
    "model = run.register_model(model_path = \"outputs/marketing_request_20210312_model.pkl\", \\\n",
    "                   model_name = \"marketing_request_20210312_model\",\\\n",
    "                  tags = {\"Training context\": \"Inline Training\"},\\\n",
    "                  properties = {\"MSE\": run.get_metrics()[\"MSE\"], \"Accuracy\": run.get_metrics()[\"Accuracy\"]})\n",
    "print(\"Model trained and registered.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "marketing_request_20210312_model\tmarketing_request_20210312_model:5\t5\n"
     ]
    }
   ],
   "source": [
    "print(model.name, model.id, model.version, sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "azureml-models\\marketing_request_20210312_model\\1\\marketing_request_20210312_model.pkl\n"
     ]
    }
   ],
   "source": [
    "print(model.get_model_path(\"marketing_request_20210312_model\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'marketing_request_20210312_model:5'"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.id"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
